{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D89B0EAB542642F98900CCC4D4E49360",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 1. 项目说明  \n",
    "## 1.1 项目概述  \n",
    "本项目旨在利用深度学习技术对扑克牌图像进行分类，基于ResNet18模型来实现对53类扑克牌的自动识别。ResNet18是一种深度残差网络模型，因其优越的特征提取能力和较少的参数量，适合用于图像分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B59C1CEE6553489E997D1248A6ECBE33",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 1.2 数据集  \n",
    "扑克牌图像数据集，包含不同类型的扑克牌图像（如：红桃A、黑桃K等）。  \n",
    "图像需要进行预处理，归一化等，以适应ResNet18模型的输入要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C791B123F4446C798D9D908D162643E",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "我使用的是**Python 3.8.5 Pytorch 1.6.0**镜像,计算资源选择**8核32G**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B791AC2203CF4B04900FD3D04B6D3F11",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6404BCC41C2C44558775CB69F21847D8",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 2. 项目实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DFC523ADAAA4935B3FE36792EF4908A",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.1 数据预处理  \n",
    "先将输入图像的大小调整为224x224像素  \n",
    "再将图像转换为PyTorch的张量格式  \n",
    "然后对图像进行归一化处理。具体来说，它使用给定的均值和标准差对每个通道（红、绿、蓝）的像素值进行归一化。这些均值和标准差值是基于在ImageNet上预训练的模型的统计数据，用于标准化图像，使其具有类似的分布，从而提高模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "810CF482643D4985AFA558B9F60AF78D",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 数据集路径\n",
    "data_dir = '/home/mw/input/cards6224/cards/'\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'valid'), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'test'), transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4ED68E314404BE896440884F4B4839A",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.2 数据集信息查看  \n",
    "查看数据的样本数量、类别和类别数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4FC61B519BE24DD590C9913A15FBDA95",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "样本数量: 7624\n",
      "类别: ['ace of clubs', 'ace of diamonds', 'ace of hearts', 'ace of spades', 'eight of clubs', 'eight of diamonds', 'eight of hearts', 'eight of spades', 'five of clubs', 'five of diamonds', 'five of hearts', 'five of spades', 'four of clubs', 'four of diamonds', 'four of hearts', 'four of spades', 'jack of clubs', 'jack of diamonds', 'jack of hearts', 'jack of spades', 'joker', 'king of clubs', 'king of diamonds', 'king of hearts', 'king of spades', 'nine of clubs', 'nine of diamonds', 'nine of hearts', 'nine of spades', 'queen of clubs', 'queen of diamonds', 'queen of hearts', 'queen of spades', 'seven of clubs', 'seven of diamonds', 'seven of hearts', 'seven of spades', 'six of clubs', 'six of diamonds', 'six of hearts', 'six of spades', 'ten of clubs', 'ten of diamonds', 'ten of hearts', 'ten of spades', 'three of clubs', 'three of diamonds', 'three of hearts', 'three of spades', 'two of clubs', 'two of diamonds', 'two of hearts', 'two of spades']\n",
      "类别数量: 53\n",
      "------------------------------------------------------------------\n",
      "Validation Dataset:\n",
      "样本数量: 265\n",
      "类别: ['ace of clubs', 'ace of diamonds', 'ace of hearts', 'ace of spades', 'eight of clubs', 'eight of diamonds', 'eight of hearts', 'eight of spades', 'five of clubs', 'five of diamonds', 'five of hearts', 'five of spades', 'four of clubs', 'four of diamonds', 'four of hearts', 'four of spades', 'jack of clubs', 'jack of diamonds', 'jack of hearts', 'jack of spades', 'joker', 'king of clubs', 'king of diamonds', 'king of hearts', 'king of spades', 'nine of clubs', 'nine of diamonds', 'nine of hearts', 'nine of spades', 'queen of clubs', 'queen of diamonds', 'queen of hearts', 'queen of spades', 'seven of clubs', 'seven of diamonds', 'seven of hearts', 'seven of spades', 'six of clubs', 'six of diamonds', 'six of hearts', 'six of spades', 'ten of clubs', 'ten of diamonds', 'ten of hearts', 'ten of spades', 'three of clubs', 'three of diamonds', 'three of hearts', 'three of spades', 'two of clubs', 'two of diamonds', 'two of hearts', 'two of spades']\n",
      "类别数量: 53\n",
      "------------------------------------------------------------------\n",
      "Test Dataset:\n",
      "样本数量: 265\n",
      "类别: ['ace of clubs', 'ace of diamonds', 'ace of hearts', 'ace of spades', 'eight of clubs', 'eight of diamonds', 'eight of hearts', 'eight of spades', 'five of clubs', 'five of diamonds', 'five of hearts', 'five of spades', 'four of clubs', 'four of diamonds', 'four of hearts', 'four of spades', 'jack of clubs', 'jack of diamonds', 'jack of hearts', 'jack of spades', 'joker', 'king of clubs', 'king of diamonds', 'king of hearts', 'king of spades', 'nine of clubs', 'nine of diamonds', 'nine of hearts', 'nine of spades', 'queen of clubs', 'queen of diamonds', 'queen of hearts', 'queen of spades', 'seven of clubs', 'seven of diamonds', 'seven of hearts', 'seven of spades', 'six of clubs', 'six of diamonds', 'six of hearts', 'six of spades', 'ten of clubs', 'ten of diamonds', 'ten of hearts', 'ten of spades', 'three of clubs', 'three of diamonds', 'three of hearts', 'three of spades', 'two of clubs', 'two of diamonds', 'two of hearts', 'two of spades']\n",
      "类别数量: 53\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集的基本信息\n",
    "def print_dataset_info(dataset, name):\n",
    "    print(f'{name} Dataset:')\n",
    "    print(f'样本数量: {len(dataset)}')\n",
    "    print(f'类别: {dataset.classes}')\n",
    "    print(f'类别数量: {len(dataset.classes)}')\n",
    "    print('------------------------------------------------------------------')\n",
    "\n",
    "print_dataset_info(train_dataset, 'Training')\n",
    "print_dataset_info(valid_dataset, 'Validation')\n",
    "print_dataset_info(test_dataset, 'Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A65B1C9C70B5497ABE7915AF666269B6",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.3 模型选择  \n",
    "这里选择的是ResNet18模型  \n",
    "ResNet18是深度卷积神经网络（CNN）中的一种经典模型，属于残差网络（Residual Network）系列，主要特点是引入了“残差块”（Residual Block）来缓解深层网络训练中的梯度消失问题。  \n",
    "其主要特点有：  \n",
    "残差学习： 使用残差块来学习输入和输出之间的“残差”，即输入与经过卷积处理后的输出之间的差异。这种结构使得网络能够更有效地训练深层模型。  \n",
    "网络结构： ResNet18包含18层可训练参数，包括卷积层、批归一化层（Batch Normalization）和激活函数（ReLU）。它由多个残差块组成，每个残差块内有两个3x3的卷积层。  \n",
    "性能优势： 相较于传统深度网络，ResNet18在训练更深的网络时表现出更好的性能和稳定性，主要因为残差结构允许梯度更容易地通过网络进行传播。  \n",
    "应用广泛： ResNet18作为一个轻量级模型，在各种视觉任务中（如图像分类、目标检测）表现出色，并且作为预训练模型在多个应用中被广泛使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "16BEDEF83DF24B65ABB0E52615CECDCB",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/mw/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde00064f85f4680b2c989e831af2e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=53, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载ResNet18模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 替换最后一层全连接层\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 53)  # 53是类别数量\n",
    "\n",
    "# 将模型转到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "C0E987E98B3243AB90BCEB0B090E0509",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB7D1762C956439F987B4C43C5C1D36B",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.4 定义训练模型函数  \n",
    "在每个训练周期（epoch）结束时输出训练损失。  \n",
    "设置训练模式 (model.train()): 切换模型到训练模式  \n",
    "数据转移到设备 (images, labels.to(device)): 将数据转移到计算设备（如 GPU）。  \n",
    "梯度清零 (optimizer.zero_grad()): 在每次迭代之前清除之前计算的梯度。  \n",
    "前向传播 (outputs = model(images)): 计算模型输出。  \n",
    "计算损失 (loss = criterion(outputs, labels)): 使用损失函数计算预测值与实际标签之间的差距。  \n",
    "反向传播 (loss.backward()): 计算梯度。  \n",
    "更新模型参数 (optimizer.step()): 根据梯度更新模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8BC76ADB36C543309822556A195D49D7",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # 设置模型为训练模式\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # 将数据转移到指定设备（CPU或GPU）\n",
    "            \n",
    "            optimizer.zero_grad() # 清除之前的梯度\n",
    "            \n",
    "            outputs = model(images) # 前向传播\n",
    "            loss = criterion(outputs, labels) # 计算损失\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step() # 更新参数\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)  # 累加损失\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset) # 计算平均损失\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        validate_model(model, valid_loader, criterion)  # 在每个周期结束后进行验证\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AA9DE2D1834DF3A334C039E4E659E2",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.5定义验证模型函数  \n",
    "在每个训练周期后验证模型的性能，并计算验证集上的损失和准确率。  \n",
    "设置评估模式 (model.eval()): 切换模型到评估模式，以禁用 Dropout 和 BatchNorm 等训练特定的层。  \n",
    "禁用梯度计算 (with torch.no_grad()): 在验证时不需要计算梯度，从而节省内存和计算资源。  \n",
    "前向传播和计算损失 (outputs = model(images), loss = criterion(outputs, labels)): 与训练时相同。  \n",
    "获取预测结果 (_, predicted = torch.max(outputs, 1)): 找到每个样本的预测类别。  \n",
    "计算总样本数和正确预测数 (total, correct): 用于计算准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6ACA6533D4144D93845AD7D100D5D600",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_model(model, valid_loader, criterion):\n",
    "    model.eval() # 设置模型为评估模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1) # 获取预测结果\n",
    "            total += labels.size(0) # 计算总样本数\n",
    "            correct += (predicted == labels).sum().item() # 计算正确预测的样本数\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    accuracy = correct / total * 100 # 计算准确率\n",
    "    print(f'Validation Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "679489BE54354B9EADEFB404E5C0D772",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.6模型训练及模型评估  \n",
    "训练模型用的是8核32G的资源,要一会儿,这边建议直接加载训练好的模型,模型地址在文章最下面  \n",
    "\n",
    "使用验证数据集评估模型性能，确保其在新数据上的泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BED605A2ACE149B39171BB90FD9616AB",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.8703\n",
      "Validation Loss: 0.4942, Accuracy: 89.06%\n",
      "Epoch 2/10, Loss: 0.5120\n",
      "Validation Loss: 0.1928, Accuracy: 96.60%\n",
      "Epoch 3/10, Loss: 0.1796\n",
      "Validation Loss: 0.1454, Accuracy: 96.23%\n",
      "Epoch 4/10, Loss: 0.0749\n",
      "Validation Loss: 0.0962, Accuracy: 98.49%\n",
      "Epoch 5/10, Loss: 0.0399\n",
      "Validation Loss: 0.0959, Accuracy: 98.11%\n",
      "Epoch 6/10, Loss: 0.0247\n",
      "Validation Loss: 0.0598, Accuracy: 99.25%\n",
      "Epoch 7/10, Loss: 0.0194\n",
      "Validation Loss: 0.0939, Accuracy: 98.49%\n",
      "Epoch 8/10, Loss: 0.0180\n",
      "Validation Loss: 0.0556, Accuracy: 98.87%\n",
      "Epoch 9/10, Loss: 0.0240\n",
      "Validation Loss: 0.0797, Accuracy: 98.11%\n",
      "Epoch 10/10, Loss: 0.0338\n",
      "Validation Loss: 0.1552, Accuracy: 95.09%\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2669204CE9AE4CD89A8B242F311EF69C",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.7 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DA8F26A1FA97403188B45D9530F6A2F0",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/home/mw/project/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6408FC87593E480FA14079318254959F",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 2.8 预测及可视化  \n",
    "对测试图像进行预测，并通过图像和预测结果的可视化展示预测的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7FA970AB098A4EBE9421E2343671A49B",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载测试集种类标签\n",
    "classes = test_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2A30D31A22E4A6D95596DF871D4BD5F",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### **加载测试集预测及可视化**  \n",
    "定义测试集预测函数，加载训练好的模型对测试集进行预测并查看部分结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7A91FF59246D43128EF4A9E49A55CF37",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/upload/rt/7A91FF59246D43128EF4A9E49A55CF37/sjkt4ypqua.png\">"
      ],
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_predictions(model, test_loader, dataset, num_images=5):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for i in range(inputs.size(0)):\n",
    "                if images_so_far == num_images:\n",
    "                    return\n",
    "                images_so_far += 1\n",
    "                \n",
    "                ax = plt.subplot(num_images // 5, 5, images_so_far)\n",
    "                ax.imshow(inputs[i].permute(1, 2, 0).cpu().numpy())\n",
    "                ax.set_title(f'Pred: {dataset[preds[i].item()]} \\nTrue: {dataset[labels[i].item()]}')\n",
    "                ax.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 使用训练好的模型进行预测可视化\n",
    "visualize_predictions(model, test_loader, classes, num_images=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92E453972D094F41A4882476340BA507",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### **随机在测试集选择一张图片加载训练好的模型进行预测并展示其类别及预测类别**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0AB2BC11772340CA9D9C2E0BA5464BE7",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_single_prediction(model, test_loader):\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "    \n",
    "    # 随机选择一张图片\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    index = np.random.randint(0, len(images))\n",
    "    img = images[index]\n",
    "    true_label = labels[index].item()\n",
    "    true_class = classes[true_label]\n",
    "\n",
    "    # 进行模型预测\n",
    "    with torch.no_grad():\n",
    "        output = model(img.unsqueeze(0))  # 增加一个批次维度\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        predicted_label = predicted.item()\n",
    "        pre_class = classes[predicted_label]\n",
    "\n",
    "    # 图像转换为numpy格式以便显示\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # 绘制图像及预测结果\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'True Label: {true_class}, Predicted Label: {pre_class}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "49ADF22EF45E48F683F0756CB5630524",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/upload/rt/49ADF22EF45E48F683F0756CB5630524/sjktdxlkhv.png\">"
      ],
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_single_prediction(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ADB561A3ACB4952963B9AB6C067FFA6",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### **对测试集进行测试，展示混淆矩阵显示结果**  \n",
    "更加直观的展示正确预测及错误预测的量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "C7C8AD53F3884D2F80B6CDDE0160C748",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.kesci.com/upload/rt/C7C8AD53F3884D2F80B6CDDE0160C748/sjkth6bh7o.png\">"
      ],
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_confusion_matrix(model, test_loader, num_classes):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(num_classes)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# 使用训练好的模型绘制混淆矩阵\n",
    "plot_confusion_matrix(model, test_loader, num_classes=53)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8865E2A4B87F404E976AA5200AC2B12E",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 加载保存的模型  \n",
    "由于模型是刚训练的不用加载,所以放到最后,如果不想训练的直接加载即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "id": "6C039FCFDE764BFE899578741824C7D6",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=53, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('/home/mw/project/model.pth')\n",
    "model.eval()  # 切换到评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECCFAC1082F848D1ADBFADC0BF14EF76",
    "jupyter": {},
    "notebookId": "66de9cf3897851404c44a47e",
    "runtime": {
     "execution_status": null,
     "is_visible": false,
     "status": "default"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 3. 总结  \n",
    "本项目展示了如何使用ResNet18对扑克牌图像进行分类，利用深度学习技术实现高效的图像识别，结果显示出了一定的准确性。未来可以探索更复杂的模型或数据增强技术，以进一步提高分类准确率和系统鲁棒性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
